{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BINARY CLASSIFICATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
    "num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISCOVERING THE DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
       "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPPING INTEGER SEQUENCE TO THE CORRESPONDING SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict(\n",
    "[(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join(\n",
    "[reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARING THE DATA : ONE HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences) , dimension))\n",
    "    \n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i,sequence] = 1\n",
    "    return(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILDING A NAIVE NEURAL NETWORK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation = 'relu' , input_shape = (10000,)))\n",
    "model.add(layers.Dense(16, activation = 'relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras import metrics\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001) ,loss='binary_crossentropy' , metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 1s 77us/step - loss: 0.5377 - binary_accuracy: 0.7774 - val_loss: 0.4050 - val_binary_accuracy: 0.8673\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 1s 61us/step - loss: 0.3144 - binary_accuracy: 0.9010 - val_loss: 0.3222 - val_binary_accuracy: 0.8775\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 1s 78us/step - loss: 0.2298 - binary_accuracy: 0.9270 - val_loss: 0.2793 - val_binary_accuracy: 0.8911\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.1772 - binary_accuracy: 0.9433 - val_loss: 0.2744 - val_binary_accuracy: 0.8890\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.1423 - binary_accuracy: 0.9558 - val_loss: 0.2889 - val_binary_accuracy: 0.8851\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 1s 74us/step - loss: 0.1192 - binary_accuracy: 0.9647 - val_loss: 0.3103 - val_binary_accuracy: 0.8788\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 1s 74us/step - loss: 0.1003 - binary_accuracy: 0.9715 - val_loss: 0.3196 - val_binary_accuracy: 0.8797\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.0813 - binary_accuracy: 0.9777 - val_loss: 0.3770 - val_binary_accuracy: 0.8676\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 1s 75us/step - loss: 0.0712 - binary_accuracy: 0.9805 - val_loss: 0.4640 - val_binary_accuracy: 0.8514\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 1s 76us/step - loss: 0.0540 - binary_accuracy: 0.9876 - val_loss: 0.3848 - val_binary_accuracy: 0.8759\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 1s 76us/step - loss: 0.0491 - binary_accuracy: 0.9881 - val_loss: 0.3944 - val_binary_accuracy: 0.8754\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 1s 77us/step - loss: 0.0389 - binary_accuracy: 0.9925 - val_loss: 0.4186 - val_binary_accuracy: 0.8752\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 1s 74us/step - loss: 0.0302 - binary_accuracy: 0.9944 - val_loss: 0.4801 - val_binary_accuracy: 0.8648\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 1s 75us/step - loss: 0.0245 - binary_accuracy: 0.9958 - val_loss: 0.4843 - val_binary_accuracy: 0.8710\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 1s 86us/step - loss: 0.0175 - binary_accuracy: 0.9981 - val_loss: 0.5092 - val_binary_accuracy: 0.8690\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 1s 76us/step - loss: 0.0144 - binary_accuracy: 0.9985 - val_loss: 0.5442 - val_binary_accuracy: 0.8680\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 1s 77us/step - loss: 0.0110 - binary_accuracy: 0.9991 - val_loss: 0.5937 - val_binary_accuracy: 0.8636\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 1s 78us/step - loss: 0.0085 - binary_accuracy: 0.9991 - val_loss: 0.6075 - val_binary_accuracy: 0.8680\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 1s 79us/step - loss: 0.0072 - binary_accuracy: 0.9991 - val_loss: 0.6360 - val_binary_accuracy: 0.8670\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 1s 76us/step - loss: 0.0036 - binary_accuracy: 0.9999 - val_loss: 0.6714 - val_binary_accuracy: 0.8658\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train , partial_y_train ,epochs = 20, batch_size=512 , validation_data=(x_val , y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdd63136c88>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##PLOT THE HISTORY OF THE TRAINING\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(history_dict['binary_accuracy']) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values , 'bo' , label='Training Loss')\n",
    "plt.plot(epochs, val_loss_values , 'b' , label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that w overfit at the 4th epoch, so we will stop to train after 4 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 1s 56us/step - loss: 0.4356 - acc: 0.8159\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 1s 48us/step - loss: 0.2528 - acc: 0.9080\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 1s 48us/step - loss: 0.1939 - acc: 0.9302\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 1s 49us/step - loss: 0.1629 - acc: 0.9408\n",
      "25000/25000 [==============================] - 1s 35us/step\n"
     ]
    }
   ],
   "source": [
    "#Training from scratch for 4 epochs\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "#Evaluation on test\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.88196\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy is ' , results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICTIONS ON TEST\n",
    "\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRYING VARIOUS IMPLEMENTATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 1s 54us/step - loss: 0.4552 - acc: 0.8235\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 1s 49us/step - loss: 0.2791 - acc: 0.9054\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 1s 52us/step - loss: 0.2207 - acc: 0.9251\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 1s 48us/step - loss: 0.1875 - acc: 0.9358\n",
      "25000/25000 [==============================] - 1s 32us/step\n"
     ]
    }
   ],
   "source": [
    "#One hidden layer\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "#Evaluation on test\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print('Accuracy is ' , results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 61us/step - loss: 0.4549 - acc: 0.8194\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 1s 48us/step - loss: 0.2532 - acc: 0.9087\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 1s 48us/step - loss: 0.1918 - acc: 0.9309\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 1s 48us/step - loss: 0.1583 - acc: 0.9428\n",
      "25000/25000 [==============================] - 1s 33us/step\n",
      "Accuracy is  0.8808\n"
     ]
    }
   ],
   "source": [
    "#Three hidden layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "#Evaluation on test\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print('Accuracy is ' , results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 0.4251 - acc: 0.8097\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 2s 68us/step - loss: 0.2347 - acc: 0.9108\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 2s 63us/step - loss: 0.1726 - acc: 0.9364\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 66us/step - loss: 0.1459 - acc: 0.9450\n",
      "25000/25000 [==============================] - 1s 43us/step\n",
      "Accuracy is  0.8756\n"
     ]
    }
   ],
   "source": [
    "#Two hidden layers with 64 units\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "#Evaluation on test\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print('Accuracy is ' , results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 67us/step - loss: 0.4279 - acc: 0.8143\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 1s 58us/step - loss: 0.2443 - acc: 0.9115\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 1s 56us/step - loss: 0.1932 - acc: 0.9286\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s 64us/step - loss: 0.1577 - acc: 0.9420\n",
      "25000/25000 [==============================] - 1s 46us/step\n",
      "Accuracy is  0.88076\n"
     ]
    }
   ],
   "source": [
    "#Two hidden layers with 32 units\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "#Evaluation on test\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print('Accuracy is ' , results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 1s 55us/step - loss: 0.1458 - acc: 0.8251\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 1s 48us/step - loss: 0.0771 - acc: 0.9107\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 1s 49us/step - loss: 0.0576 - acc: 0.9320\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 1s 49us/step - loss: 0.0479 - acc: 0.9430\n",
      "25000/25000 [==============================] - 1s 32us/step\n",
      "Accuracy is  0.87992\n"
     ]
    }
   ],
   "source": [
    "#Two hidden layers with MSE LOSS FUNCTION\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='mse',\n",
    "metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "#Evaluation on test\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print('Accuracy is ' , results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 2s 60us/step - loss: 0.4433 - acc: 0.8310\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 1s 49us/step - loss: 0.2468 - acc: 0.9126\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 1s 49us/step - loss: 0.1839 - acc: 0.9340\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 1s 52us/step - loss: 0.1527 - acc: 0.9458\n",
      "25000/25000 [==============================] - 1s 32us/step\n",
      "Accuracy is  0.8782\n"
     ]
    }
   ],
   "source": [
    "#Two hidden layers  with TANH\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "\n",
    "#Evaluation on test\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print('Accuracy is ' , results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTI CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
    "num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISCOVERING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n",
      "2246\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 0s 1us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict(\n",
    "[(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join(\n",
    "[reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "print (decoded_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARING THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot enconding of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot enconding of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)\n",
    "\n",
    "print(one_hot_train_labels)\n",
    "print(one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi faire avec keras.to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILDING NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 128us/step - loss: 2.4997 - acc: 0.4899 - val_loss: 1.6813 - val_acc: 0.6480\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 68us/step - loss: 1.3915 - acc: 0.7038 - val_loss: 1.2790 - val_acc: 0.7190\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 68us/step - loss: 1.0487 - acc: 0.7699 - val_loss: 1.1181 - val_acc: 0.7610\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 68us/step - loss: 0.8246 - acc: 0.8282 - val_loss: 1.0217 - val_acc: 0.7760\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 76us/step - loss: 0.6599 - acc: 0.8637 - val_loss: 0.9688 - val_acc: 0.7970\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 69us/step - loss: 0.5254 - acc: 0.8931 - val_loss: 0.9200 - val_acc: 0.8090\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 69us/step - loss: 0.4291 - acc: 0.9118 - val_loss: 0.9108 - val_acc: 0.8030\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 78us/step - loss: 0.3497 - acc: 0.9277 - val_loss: 0.8937 - val_acc: 0.8150\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 70us/step - loss: 0.2893 - acc: 0.9386 - val_loss: 0.9128 - val_acc: 0.8090\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 68us/step - loss: 0.2450 - acc: 0.9453 - val_loss: 0.9114 - val_acc: 0.8100\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 71us/step - loss: 0.2102 - acc: 0.9481 - val_loss: 0.9482 - val_acc: 0.8130\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 78us/step - loss: 0.1878 - acc: 0.9528 - val_loss: 0.9613 - val_acc: 0.8040\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 69us/step - loss: 0.1658 - acc: 0.9529 - val_loss: 0.9926 - val_acc: 0.8010\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 69us/step - loss: 0.1532 - acc: 0.9550 - val_loss: 0.9772 - val_acc: 0.8050\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 70us/step - loss: 0.1456 - acc: 0.9550 - val_loss: 1.0188 - val_acc: 0.7990\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 70us/step - loss: 0.1326 - acc: 0.9554 - val_loss: 1.0390 - val_acc: 0.8000\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 71us/step - loss: 0.1255 - acc: 0.9554 - val_loss: 1.0423 - val_acc: 0.7970\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 71us/step - loss: 0.1170 - acc: 0.9560 - val_loss: 1.0367 - val_acc: 0.8150\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 69us/step - loss: 0.1157 - acc: 0.9573 - val_loss: 1.0295 - val_acc: 0.8080\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 70us/step - loss: 0.1136 - acc: 0.9583 - val_loss: 1.0501 - val_acc: 0.8030\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "partial_y_train,\n",
    "epochs=20,\n",
    "batch_size=512,\n",
    "validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xt8FOXZ//HPxUlAjgYEBAlo8UgBMcX6CEq1tWAVPFVF/FVFi9riqbWVKk/1oWLVqg+19bGi1dqSirYUD61ilVLRWpVQCSgoIIJGEAER5KAhcP3+uCfLZtkkm2Q3u0m+79drXjs7c8/stZPNXHPfM3OPuTsiIiIAzbIdgIiI5A4lBRERiVFSEBGRGCUFERGJUVIQEZEYJQUREYlRUpC9mFlzM9tqZr3TWTabzOxLZpb266/N7Otmtiru/TtmNiyVsrX4rAfN7IbaLi+SihbZDkDqzsy2xr1tC3wB7IreX+buhTVZn7vvAtqlu2xT4O6HpmM9ZnYpcIG7D49b96XpWLdIVZQUGgF3j+2UoyPRS939hcrKm1kLdy+rj9hEqqPfY25R81ETYGa3mNljZvaomX0GXGBmx5rZq2b2qZmtNbN7zKxlVL6FmbmZ9YneT4/mP2tmn5nZv82sb03LRvNHmtkyM9tsZr8ys3+Z2UWVxJ1KjJeZ2Qoz22Rm98Qt29zM/tfMNprZu8CIKrbPJDObkTDtXjO7Oxq/1MyWRt/n3egovrJ1lZjZ8Gi8rZn9IYrtLeDoJJ+7MlrvW2Y2Kpr+ZeDXwLCoaW5D3La9OW75y6PvvtHMnjCzHqlsm5ps5/J4zOwFM/vEzD4ysx/Hfc5/R9tki5kVmdkByZrqzOzl8r9ztD3nRZ/zCTDJzPqZ2dzou2yItlvHuOXzo++4Ppr/SzNrHcV8eFy5Hma23czyKvu+Ug1319CIBmAV8PWEabcApcBphAOBNsBXgGMItcWDgGXAhKh8C8CBPtH76cAGoABoCTwGTK9F2f2Bz4DR0bwfADuBiyr5LqnE+CTQEegDfFL+3YEJwFtALyAPmBd+7kk/5yBgK7Bv3Lo/Bgqi96dFZQw4EdgBDIjmfR1YFbeuEmB4NH4n8E+gM5APLEkoew7QI/qbnB/F0C2adynwz4Q4pwM3R+MnRzEOAloD/wf8I5VtU8Pt3BFYB1wN7AN0AIZE834CFAP9ou8wCNgP+FLitgZeLv87R9+tDLgCaE74PR4CnAS0in4n/wLujPs+b0bbc9+o/HHRvGnAlLjP+SEwK9v/hw15yHoAGtL8B608KfyjmuWuA/4UjSfb0f8mruwo4M1alB0HvBQ3z4C1VJIUUozxq3Hz/wJcF43PIzSjlc87JXFHlbDuV4Hzo/GRwLIqyv4V+H40XlVSeD/+bwF8L75skvW+CXwrGq8uKTwC3Bo3rwPhPFKv6rZNDbfz/wOKKin3bnm8CdNTSQorq4nhbGB+ND4M+AhonqTcccB7gEXvFwJnpvv/qikNaj5qOj6If2Nmh5nZ36LmgC3AZKBLFct/FDe+napPLldW9oD4ODz8F5dUtpIUY0zps4DVVcQL8EdgTDR+PhA7OW9mp5rZa1HzyaeEo/SqtlW5HlXFYGYXmVlx1ATyKXBYiuuF8P1i63P3LcAmoGdcmZT+ZtVs5wOBFZXEcCAhMdRG4u+xu5k9bmYfRjH8LiGGVR4uaqjA3f9FqHUMNbP+QG/gb7WMSdA5haYk8XLM+wlHpl9y9w7ATwlH7pm0lnAkC4CZGRV3YonqEuNaws6kXHWXzD4GfN3MehGat/4YxdgG+DPwc0LTTifg7ynG8VFlMZjZQcB9hCaUvGi9b8ett7rLZ9cQmqTK19ee0Ez1YQpxJapqO38AHFzJcpXN2xbF1DZuWveEMonf73bCVXNfjmK4KCGGfDNrXkkcvwcuINRqHnf3LyopJylQUmi62gObgW3RibrL6uEz/woMNrPTzKwFoZ26a4ZifBy4xsx6Ricdr6+qsLuvIzRxPAy84+7Lo1n7ENq51wO7zOxUQtt3qjHcYGadLNzHMSFuXjvCjnE9IT9eSqgplFsH9Io/4ZvgUeASMxtgZvsQktZL7l5pzasKVW3np4DeZjbBzFqZWQczGxLNexC4xcwOtmCQme1HSIYfES5oaG5m44lLYFXEsA3YbGYHEpqwyv0b2AjcauHkfRszOy5u/h8IzU3nExKE1IGSQtP1Q+BCwonf+wlHyhkV7XjPBe4m/JMfDLxBOEJMd4z3AXOAxcB8wtF+df5IOEfwx7iYPwWuBWYRTtaeTUhuqbiJUGNZBTxL3A7L3RcB9wCvR2UOA16LW/Z5YDmwzszim4HKl59NaOaZFS3fGxibYlyJKt3O7r4Z+AZwFuHE9jLghGj2L4AnCNt5C+Gkb+uoWfC7wA2Eiw6+lPDdkrkJGEJITk8BM+NiKANOBQ4n1BreJ/wdyuevIvydS939lRp+d0lQfnJGpN5FzQFrgLPd/aVsxyMNl5n9nnDy+uZsx9LQ6eY1qVdmNoLQHPA54ZLGMsLRskitROdnRgNfznYsjYGaj6S+DQVWEpoVRgCn68Sg1JaZ/Zxwr8St7v5+tuNpDNR8JCIiMaopiIhITIM7p9ClSxfv06dPtsMQEWlQFixYsMHdq7oEHGiASaFPnz4UFRVlOwwRkQbFzKq7qx9Q85GIiMRRUhARkRglBRERiVFSEBGRGCUFERGJUVIQEclxhYXQpw80axZeCwurW6L2lBREJOfVdafYkJcvLITx42H1anAPr+PHZzAxZPvRbzUdjj76aBeR+jV9unt+vrtZeJ0+vf6Wnz7dvW1b97BLDEPbtqmvo6Evn59fcdnyIT8/teXLUcljVROHrO/kazooKUhT1JR3ynXdKTb05c2SL2+W2vLllBREGommvlOu606xoS9f3zUFnVMQybC6tkffeCNs315x2vbtYXp9LP9+JR1SVzY93cv3ruTp2pVNb2zLT5kCbdtWnNa2bZieEalkjlwaVFOQ+pbNphf3hn+kWtfls11Tyvby5euoS/Ohe+o1hazv5Gs6KClIfcp200s61tHQd8rl68jWOZVcWD4dlBRE0iDb7eHu2ilLeigpiETqskPKdtNLOr5DOpaXhi/VpNDgHsdZUFDgep6CpKr8xp/4E61t28K0aTB2bPXL9+kTbhZKlJ8Pq1Zl/vNF0sXMFrh7QXXldPWRNGp1vfKmrld+jB0bEkB+PpiFVyUEyWWqKUij1qxZaLBJZAa7d6e2jsLCkETefz9cRjhlinbq0vCopiCNRl2u86/rNeIQEsCqVSGJrFqlhCCNm5KC5LS6dgZW7zf+iDRwSgqS0+p6TkBt+iI1o3MKktPScU5ARHROQRqJdJwTEJHUKSlITtM5AZH6paQgOU3nBETql5KCZFxdu47WJaEi9adFtgOQxi2xm4fyS0pBO3eRXKSagmRUXS8pFZH6paQgGVXXp26JSP1SUpCM0iWlIg1LRpOCmY0ws3fMbIWZTUwyP9/M5pjZIjP7p5n1ymQ8Uv90SalIw5KxpGBmzYF7gZHAEcAYMzsiodidwO/dfQAwGfh5puKR7NAlpSINSyavPhoCrHD3lQBmNgMYDSyJK3MEcG00Phd4IoPxSJaMHaskINJQZLL5qCfwQdz7kmhavGLgrGj8DKC9meUlrsjMxptZkZkVrV+/PiPBSuXqep+BiDQcmUwKlmRaYtdm1wEnmNkbwAnAh0DZXgu5T3P3Ancv6Nq1a/ojlUrVtetqEWlYMpkUSoAD4973AtbEF3D3Ne5+prsfBdwYTducwZikhnSfgUjTksmkMB/oZ2Z9zawVcB7wVHwBM+tiZuUx/AR4KIPxSC3oPgORpiVjScHdy4AJwHPAUuBxd3/LzCab2aio2HDgHTNbBnQDdKFijtF9BiJNS0b7PnL3Z4BnEqb9NG78z8CfMxmD1M2UKRX7LgLdZyDSmOmOZqmS7jMQaVrUS6pUS/cZiDQdqimIiEiMkoKIiMQoKYiISIySgoiIxCgpNAHqu0hEUqWrjxo5PSNZRGpCNYVGTn0XiUhNKCk0cuq7SERqQkmhkVPfRSJSE0oKjZyekSwiNaGk0Mip7yIRqQldfdQEqO8iEUmVagoiIhKjpCAiIjFKCiIiEqOkICIiMUoKIiISo6QgIiIxSgoiIhKjpNAAqOtrEakvunktx6nraxGpT6op5Dh1fS0i9UlJIcep62sRqU9KCjlOXV+LSH1SUshx6vpaROqTkkKOU9fXIlKfdPVRA6Cur4Ndu6B582xHIU3V7t3hsvDGTklBctrSpTBrVhgWLICePeHww+Gwwyq+dusWalK5xh22bYMNG2DrVjjkEGjVKttRSU28+y7ccQc88gjstx8MGgQDB+4ZDjmkcR2sKClITnGH+fP3JIJ33gnThwyBH/0I1qyBt9+Ghx8OO9lyHTsmTxZ9+0KLNP7KS0vDDj7ZsH598mlffLFn+TZt4JhjYNiwMHz1q9C+ffrik/RZtAhuuw0eeyz8hs4/P9RWi4vh+eehrCyUa90a+vevmCwGDAi/yYbI3D3bMdRIQUGBFxUVZTuMJqW0FF58EYqKwh3Vhx8ejo4ST4DX1s6dMG9eSAJPPAEffhiOvIYPhzPOgNGjoVevisu4h3JLl4YkEf/60Ud7yrVqBf36hSRx0EFhudLSsKOOHxKnJSuzY0fFRJSoUyfo0gW6dg2v8UPXriGW+fPhpZdg4cLQHNG8ediZDBsGQ4eGoVu39GxXqZ1XXoFbb4W//Q3atYMrroBrr4UePfaUKS0Nv7WFC0OSKB82btxTpk+fvWsV+fnZq1WY2QJ3L6i2nJKCJLNtG8yeHXbUf/0rbN5ccX75Se/EI/PDDgs7wOps3w5//3tY/9NPw6ZN4Sj6m98MieDUU0NVvTY+/TTUMBITxqpV4R9yn33C0KrVnvHE98nmtW69986+fIe/337QsmXqMW7ZAq++GhLEyy+H8c8/D/MOOSQkh/LaxEEH5WbTWGPiHn6Pt94aDlDy8uDqq2HCBOjcOfV1fPhhxSRRXAzLloV5EH4j+fnhb1o+9O27Z7xTp8x9x5xICmY2Avgl0Bx40N1vS5jfG3gE6BSVmejuz1S1TiWFzNm4MeygZ80K/yCffx52dqNGhR31sGHJj87ffjscRZfLy6uYJMrHO3aEZ54J6589OyzTuTOcdlpY/8knp6/20dCUloZzJi+/vCdRbNoU5vXoEZLEf/1XqDHF10by8tLXPLZ7d2ju+vDD5MOGDeH+mPiDgEMPhQ4d0vP52bBrF/zlL/Dzn8Mbb4RzVtddB9/9Luy7b3o+Y9s2ePPN0Bz17rvw3nuwcmUYPvmkYtnOnSsmifjx3r3rdj4q60nBzJoDy4BvACXAfGCMuy+JKzMNeMPd7zOzI4Bn3L1PVetVUkivDz4ITTazZoUjpF274MAD4fTT9ySC6nY6u3eH9SRLFh9/vHf5nj33rP/442t2hN1U7N4dtuNLL+0ZPvggednOnfeuuSR736FD1Tv9tWtDU168Zs2ge3c44ICQgN5/H5Yv39OeDuHvGZ/8y1979MjdGk5pKUyfDrffHo7k+/WD66+HCy4INcP6snlzxSSxcuWe96tWhTjLNWsG994Ll19eu89KNSlk8kTzEGCFu6+MApoBjAaWxJVxoPw4oyOwJoPxCKEam3hFD4R/4uuvDzvqo4+u2T9zs2ahSpyfDyNGVJy3ceOeppz16+HEE6GgoGlc2lcXzZrBkUeGoXwnsG5dGCo7sb1+fdhp/+c/YTx+h5JMu3Zhh96zJ5xwwp7x+KFbt70PCnbuDDutxIOA3/8ePvtsT7kOHfYki8MOCzveZs0qP2dT3XmdsrI9520qS4B5eVUfZGzbBg8+CHfeCSUloc3/scfgrLOy09bfsWOIYdCgveft3h0urIhPGEcfnfmYMllTOBsY4e6XRu//H3CMu0+IK9MD+DvQGdgX+Lq7L0iyrvHAeIDevXsfvXr16ozE3JiVlISjjL/8JRwZQbii54wzwnDoodmNT9Kr/FLY+MTx6adhJ1q+w093s497qG0knvh/++1QE0lF+bmcZOd3WrQI32HDhnBOpjLxiSM+abiHq9Y2bgw14BtuCOewcrU2k265UFNItqkTM9AY4HfufpeZHQv8wcz6u/vuCgu5TwOmQWg+yki0jdSWLaGKfPfd4Qhv+HC46qrQfNOzZ7ajk0wxCzWBdu1Cu3R9feYBB4ThxBMrztuyJRzpmlV+Mr9ly9R30KWlYede2WXA5eMffBDOFZRfGnzKKfCTn4RzNJJcJpNCCXBg3Pte7N08dAkwAsDd/21mrYEuQJKWaKmJnTvhgQfg5pvDP8TYsaG/pPz8bEcmTVGHDsmbSGqrVatwziL+MtGquIf/Cd04WL1MtuzOB/qZWV8zawWcBzyVUOZ94CQAMzscaA2sz2BMjZ47PPlkuJnm+98PbdLz54eTakoI0lSZKSGkKmNJwd3LgAnAc8BS4HF3f8vMJpvZqKjYD4Hvmlkx8ChwkTe0GydyyOuvhxOGp58eTug99RT84x/hxK6ISCoy2s1FdM/BMwnTfho3vgQ4LpMxNAXvvRdOms2YAfvvD/fdB5demt7uHUSkadBuowHbtCmcJ/jVr8LldJMmwY9/rL50RKT2lBQaoNJS+L//g8mTwyV6F10UxhP7BxIRqSndQtSAuMOf/gRHHBE66CooCJfbPfSQEoKIpIeSQgNQVhauKDruODjnnNBx3OzZoX+igQOzHZ2INCZKCvWgsDB0o9usWXgtLExtuZUr4cYbQ0dYp58eujD47W9Dd73f/GYmIxaRpkrnFDKssBDGjw9dRQOsXh3eQ/JHbJaWhg7qHngAXnghJJKRI0Ovjd/6lq4oEpHM0vMUMqxPn5AIEuXnh14Qy73zTuio65FHwh3IvXvDJZfAuHE6XyAidZcLfR8Jocmnsuk7dsDMmaFWMG9eqAWMGhVqBd/4RuN67quINAxKChnWu3fymkJ5t8WbNsHBB4eHfFx0Uei7XkQkW3SiOcOmTEn+NLEdO8LJ4jlzQlfWEycqIYhI9qmmkGFjx4aHZVx2WUgELVqEy0p/+cvQx7uISC5RUsgwd/jXv0JCuOuucNNZU3moh4g0PEoKGTZ5Mtx/f3jU5Q9+kO1oRESqpnMKGXT//eEhNxdeGE4ki4jkOiWFDJk1C773vfD4vwceUJORiDQMSgoZMG8ejBkDQ4bA44+HZ8+KiDQESgpptnhxuAGtb1/4619h332zHZGISOqUFNJo9WoYMSLcmPbcc5CXl+2IRERqJqWkYGYHm9k+0fhwM7vKzDplNrSGZcOGcDPa9u2hW+vevbMdkYhIzaVaU5gJ7DKzLwG/BfoCf8xYVA3Mtm1w6qmhg7unnoL+/bMdkYhI7aSaFHa7exlwBjDV3a8FemQurIZj50749rdh/nyYMQOGDct2RCIitZfqzWs7zWwMcCFwWjStyV9T4x56NH32WZg2LTwIR0SkIUu1pnAxcCwwxd3fM7O+wPTMhdUw/OQn4fkHkyeH5CAi0tClVFNw9yXAVQBm1hlo7+63ZTKwXDd1Ktx+e7hBbdKkbEcjIpIeqV599E8z62Bm+wHFwMNmdndmQ8tdjz4aOrY76yy45x7drSwijUeqzUcd3X0LcCbwsLsfDXw9c2HlruefD30ZnXACTJ+up6OJSOOSalJoYWY9gHOAv2Ywnpy2YAGceSYcfjg8+SS0bp3tiERE0ivVpDAZeA54193nm9lBwPLMhZV7Vq6EkSPDg3GefRY6dsx2RCIi6ZfqieY/AX+Ke78SOCtTQeWia6+FL76Al1+GAw7IdjQiIpmR6onmXmY2y8w+NrN1ZjbTzHplOrhc8a9/hTuVr78eDjkk29GIiGROqs1HDwNPAQcAPYGno2mNnjtMnAjdu8PVV2c7GhGRzEo1KXR194fdvSwafgd0zWBcOeNvfwtNRjfdpG6wRaTxSzUpbDCzC8yseTRcAGzMZGC5YNeucNdy9+7hcZrNmkGfPlBYmO3IREQyI9WkMI5wOepHwFrgbELXF1UysxFm9o6ZrTCziUnm/6+ZLYyGZWb2aU2Cz7TCQnjzTfjkE3j//dCUtHo1jB+vxCAijZO5e+0WNLvG3adWMb85sAz4BlACzAfGRF1mJCt/JXCUu4+r6nMLCgq8qKioVjHXxBdfwKGHwtq1UFq69/z8/NBVtohIQ2BmC9y9oLpydXny2g+qmT8EWOHuK929FJgBjK6i/Bjg0TrEk1a/+U2oFSRLCBBqDiIijU1dkkJ1Pf70BD6Ie18STdt7RWb5hAf3/KOS+ePNrMjMitavX1+bWGtkyxa45RY46aRQI0hGT1YTkcaoLkmhunanZEmjsmXOA/7s7ruSfpD7NHcvcPeCrl0zf9HTXXeFx2vedhtMmQJt21ac37ZtmC4i0thUeUezmX1G8h25AW2qWXcJcGDc+17AmkrKngd8v5r11Yt160JS+Pa3oaAgDAA33hiajHr3Dglh7NjsxikikglVJgV3b1+Hdc8H+kUP5PmQsOM/P7GQmR0KdAb+XYfPSptbboHPPw+v5caOVRIQkaahLs1HVYqe6TyB0JHeUuBxd3/LzCab2ai4omOAGV7by6DSaOVKuP9+uOQSdWchIk1TrS9JzZZMXpI6dizMmgUrVqjTOxFpXOrjktRGZeFC+OMfQ/9GSggi0lQpKURuuAE6dw49oYqINFUpPU+hsXvxxfDgnDvugE6dsh2NiEj2NPmagnuoHfTqBRMmZDsaEZHsavI1hSeegNdegwcfhDbV3XkhItLINemaQllZOJdw2GFw4YXZjkZEJPuadE3hkUfg7bdh5kxo0aS3hIhI0GRrCjt2hKepHXMMnHFGtqMREckNTfb4+N574cMPYfp0sOr6exURaSKaZE3h00/h1lthxAgYPjzb0YiI5I4mmRTuuAM2bQrPXRYRkT2aXFJYswamToXzz4dBg7IdjYhIbmlySWHyZNi5M7yKiEhFTSopLFsWblK77DI4+OBsRyMiknuaVFKYNAlat4b//u9sRyIikpuaTFIoKoI//Ql+8APo1i3b0YiI5KYmkxReeQW6d4frrst2JCIiuavJJIWrroLly6FDh2xHIiKSu5pMUgBo1y7bEYiI5LYmlRRERKRqSgoiIhKjpCAiIjFKCiIiEqOkICIiMUoKIiISo6QgIiIxSgoiIhKjpCAiIjFKCiIiEqOkICIiMUoKIiISo6QgIiIxSgoiIhKT0aRgZiPM7B0zW2FmEyspc46ZLTGzt8zsj5mMR0REqtYiUys2s+bAvcA3gBJgvpk95e5L4sr0A34CHOfum8xs/0zFIyIi1ctkTWEIsMLdV7p7KTADGJ1Q5rvAve6+CcDdP85gPCIiUo1MJoWewAdx70uiafEOAQ4xs3+Z2atmNiLZisxsvJkVmVnR+vXrMxSuiIhkMilYkmme8L4F0A8YDowBHjSzTnst5D7N3QvcvaBr165pD1RERIJMJoUS4MC4972ANUnKPOnuO939PeAdQpIQEZEsyGRSmA/0M7O+ZtYKOA94KqHME8DXAMysC6E5aWUGYxIRkSpkLCm4exkwAXgOWAo87u5vmdlkMxsVFXsO2GhmS4C5wI/cfWOmYhIRkaqZe2Izf24rKCjwoqKibIchItKgmNkCdy+orpzuaBYRkRglBRERiVFSEBGRGCUFERGJUVIQEZEYJQUREYlRUhARkRglBRERiVFSEBGRGCUFERGJUVIQEZEYJQUREYlRUhARkZgW2Q5ARBqGnTt3UlJSwueff57tUKQKrVu3plevXrRs2bJWyyspiEhKSkpKaN++PX369MEs2dN2JdvcnY0bN1JSUkLfvn1rtQ41H4lISj7//HPy8vKUEHKYmZGXl1en2pySgoikTAkh99X1b6SkICIiMUoKIpIRhYXQpw80axZeCwvrtr6NGzcyaNAgBg0aRPfu3enZs2fsfWlpaUrruPjii3nnnXeqLHPvvfdSWNdgGzCdaBaRtCsshPHjYfv28H716vAeYOzY2q0zLy+PhQsXAnDzzTfTrl07rrvuugpl3B13p1mz5Me7Dz/8cLWf8/3vf792ATYSqimISNrdeOOehFBu+/YwPd1WrFhB//79ufzyyxk8eDBr165l/PjxFBQUcOSRRzJ58uRY2aFDh7Jw4ULKysro1KkTEydOZODAgRx77LF8/PHHAEyaNImpU6fGyk+cOJEhQ4Zw6KGH8sorrwCwbds2zjrrLAYOHMiYMWMoKCiIJax4N910E1/5yldi8bk7AMuWLePEE09k4MCBDB48mFWrVgFw66238uUvf5mBAwdyYyY2VgqUFEQk7d5/v2bT62rJkiVccsklvPHGG/Ts2ZPbbruNoqIiiouLef7551myZMley2zevJkTTjiB4uJijj32WB566KGk63Z3Xn/9dX7xi1/EEsyvfvUrunfvTnFxMRMnTuSNN95IuuzVV1/N/PnzWbx4MZs3b2b27NkAjBkzhmuvvZbi4mJeeeUV9t9/f55++mmeffZZXn/9dYqLi/nhD3+Ypq1TM0oKIpJ2vXvXbHpdHXzwwXzlK1+JvX/00UcZPHgwgwcPZunSpUmTQps2bRg5ciQARx99dOxoPdGZZ565V5mXX36Z8847D4CBAwdy5JFHJl12zpw5DBkyhIEDB/Liiy/y1ltvsWnTJjZs2MBpp50GhJvN2rZtywsvvMC4ceNo06YNAPvtt1/NN0QaKCmISNpNmQJt21ac1rZtmJ4J++67b2x8+fLl/PKXv+Qf//gHixYtYsSIEUmv22/VqlVsvHnz5pSVlSVd9z777LNXmfJmoKps376dCRMmMGvWLBYtWsS4ceNicSS7bNTdc+KSXyUFEUm7sWNh2jTIzwez8DptWu1PMtfEli1baN++PR06dGDt2rU899xzaf+MoUOH8vjjjwOwePHipDWRHTt20KxZM7p06cJnn33GzJkzAejcuTNdunTh6aefBsJNgdu3b+fkk0/mt7/9LTt27ADgk08+SXvcqdDVRyKSEWPH1k8SSDR48GCOOOII+vfvz0EHHcRxxx2X9s+48sor+c53vsOAAQMYPHgw/fv3p2PHjhXK5OXlceGFF9KXqlMbAAANdklEQVS/f3/y8/M55phjYvMKCwu57LLLuPHGG2nVqhUzZ87k1FNPpbi4mIKCAlq2bMlpp53Gz372s7THXh1LpRqUSwoKCryoqCjbYYg0OUuXLuXwww/Pdhg5oaysjLKyMlq3bs3y5cs5+eSTWb58OS1a5MZxdrK/lZktcPeC6pbNjW8gItKAbN26lZNOOomysjLcnfvvvz9nEkJdNY5vISJSjzp16sSCBQuyHUZG6ESziIjEKCmIiEiMkoKIiMQoKYiISExGk4KZjTCzd8xshZlNTDL/IjNbb2YLo+HSTMYjIg3X8OHD97oRberUqXzve9+rcrl27doBsGbNGs4+++xK113dpe5Tp05le1wvf6eccgqffvppKqE3KBlLCmbWHLgXGAkcAYwxsyOSFH3M3QdFw4OZikdEGrYxY8YwY8aMCtNmzJjBmDFjUlr+gAMO4M9//nOtPz8xKTzzzDN06tSp1uvLVZm8JHUIsMLdVwKY2QxgNLD3/eAi0qBccw0k6Sm6TgYNgqjH6qTOPvtsJk2axBdffME+++zDqlWrWLNmDUOHDmXr1q2MHj2aTZs2sXPnTm655RZGjx5dYflVq1Zx6qmn8uabb7Jjxw4uvvhilixZwuGHHx7rWgLgiiuuYP78+ezYsYOzzz6b//mf/+Gee+5hzZo1fO1rX6NLly7MnTuXPn36UFRURJcuXbj77rtjvaxeeumlXHPNNaxatYqRI0cydOhQXnnlFXr27MmTTz4Z6/Cu3NNPP80tt9xCaWkpeXl5FBYW0q1bN7Zu3cqVV15JUVERZsZNN93EWWedxezZs7nhhhvYtWsXXbp0Yc6cOen7I5DZpNAT+CDufQlwTJJyZ5nZ8cAy4Fp3/yBJGRFp4vLy8hgyZAizZ89m9OjRzJgxg3PPPRczo3Xr1syaNYsOHTqwYcMGvvrVrzJq1KhKO5i77777aNu2LYsWLWLRokUMHjw4Nm/KlCnst99+7Nq1i5NOOolFixZx1VVXcffddzN37ly6dOlSYV0LFizg4Ycf5rXXXsPdOeaYYzjhhBPo3Lkzy5cv59FHH+WBBx7gnHPOYebMmVxwwQUVlh86dCivvvoqZsaDDz7IHXfcwV133cXPfvYzOnbsyOLFiwHYtGkT69ev57vf/S7z5s2jb9++GekfKZNJIdlfI7FPjaeBR939CzO7HHgEOHGvFZmNB8YD9M5U37sikrKqjugzqbwJqTwplB+duzs33HAD8+bNo1mzZnz44YesW7eO7t27J13PvHnzuOqqqwAYMGAAAwYMiM17/PHHmTZtGmVlZaxdu5YlS5ZUmJ/o5Zdf5owzzoj11HrmmWfy0ksvMWrUKPr27cugQYOAyrvnLikp4dxzz2Xt2rWUlpbSt29fAF544YUKzWWdO3fm6aef5vjjj4+VyUT32pk80VwCHBj3vhewJr6Au2909y+itw8ARydbkbtPc/cCdy/o2rVrjQNJ97NiRSQ7Tj/9dObMmcN//vMfduzYETvCLywsZP369SxYsICFCxfSrVu3pN1lx0tWi3jvvfe48847mTNnDosWLeJb3/pWteupqv+48m63ofLuua+88komTJjA4sWLuf/++2Ofl6wr7froXjuTSWE+0M/M+ppZK+A84Kn4AmbWI+7tKGBpuoMof1bs6tXgvudZsUoMIg1Pu3btGD58OOPGjatwgnnz5s3sv//+tGzZkrlz57J69eoq13P88cdTGO0E3nzzTRYtWgSEbrf33XdfOnbsyLp163j22Wdjy7Rv357PPvss6bqeeOIJtm/fzrZt25g1axbDhg1L+Ttt3ryZnj17AvDII4/Epp988sn8+te/jr3ftGkTxx57LC+++CLvvfcekJnutTOWFNy9DJgAPEfY2T/u7m+Z2WQzGxUVu8rM3jKzYuAq4KJ0x1Gfz4oVkcwbM2YMxcXFsSefAYwdO5aioiIKCgooLCzksMMOq3IdV1xxBVu3bmXAgAHccccdDBkyBAhPUTvqqKM48sgjGTduXIVut8ePH8/IkSP52te+VmFdgwcP5qKLLmLIkCEcc8wxXHrppRx11FEpf5+bb76Zb3/72wwbNqzC+YpJkyaxadMm+vfvz8CBA5k7dy5du3Zl2rRpnHnmmQwcOJBzzz035c9JVaPvOrtZs1BDSGQGu3enMTCRRk5dZzccdek6u9Hf0Vzfz4oVEWnIGn1SqO9nxYqINGSNPilk81mxIo1NQ2tuborq+jdqEg/ZydazYkUak9atW7Nx40by8vIyflmk1I67s3HjRlq3bl3rdTSJpCAidderVy9KSkpYv359tkORKrRu3ZpevXrVenklBRFJScuWLWN30krj1ejPKYiISOqUFEREJEZJQUREYhrcHc1mth6oumOT7OkCbMh2EFVQfHWT6/FB7seo+OqmLvHlu3u1PYo2uKSQy8ysKJXbyLNF8dVNrscHuR+j4qub+ohPzUciIhKjpCAiIjFKCuk1LdsBVEPx1U2uxwe5H6Piq5uMx6dzCiIiEqOagoiIxCgpiIhIjJJCDZnZgWY218yWRo8SvTpJmeFmttnMFkbDT+s5xlVmtjj67L0eU2fBPWa2wswWmdngeozt0LjtstDMtpjZNQll6n37mdlDZvaxmb0ZN20/M3vezJZHr50rWfbCqMxyM7uwnmL7hZm9Hf39ZplZp0qWrfK3kOEYbzazD+P+jqdUsuwIM3sn+j1OrMf4HouLbZWZLaxk2Yxuw8r2KVn7/bm7hhoMQA9gcDTeHlgGHJFQZjjw1yzGuAroUsX8U4BnAQO+CryWpTibAx8RbqrJ6vYDjgcGA2/GTbsDmBiNTwRuT7LcfsDK6LVzNN65HmI7GWgRjd+eLLZUfgsZjvFm4LoUfgPvAgcBrYDixP+nTMWXMP8u4KfZ2IaV7VOy9ftTTaGG3H2tu/8nGv8MWAr0zG5UNTYa+L0HrwKdzKxHFuI4CXjX3bN+h7q7zwM+SZg8GngkGn8EOD3Jot8Ennf3T9x9E/A8MCLTsbn73929LHr7KlD7vpLToJLtl4ohwAp3X+nupcAMwnZPq6ris/BwiHOAR9P9uamoYp+Sld+fkkIdmFkf4CjgtSSzjzWzYjN71syOrNfAwIG/m9kCMxufZH5P4IO49yVkJ7GdR+X/iNncfuW6uftaCP+4wP5JyuTCthxHqPklU91vIdMmRE1cD1XS/JEL228YsM7dl1cyv962YcI+JSu/PyWFWjKzdsBM4Bp335Iw+z+EJpGBwK+AJ+o5vOPcfTAwEvi+mR2fMD/ZY7Pq9dpkM2sFjAL+lGR2trdfTWR1W5rZjUAZUFhJkep+C5l0H3AwMAhYS2iiSZT13yIwhqprCfWyDavZp1S6WJJpddp+Sgq1YGYtCX+8Qnf/S+J8d9/i7luj8WeAlmbWpb7ic/c10evHwCxCFT1eCXBg3PtewJr6iS5mJPAfd1+XOCPb2y/OuvJmtej14yRlsrYto5OKpwJjPWpgTpTCbyFj3H2du+9y993AA5V8dlZ/i2bWAjgTeKyyMvWxDSvZp2Tl96ekUENR++NvgaXufnclZbpH5TCzIYTtvLGe4tvXzNqXjxNOSL6ZUOwp4DvRVUhfBTaXV1PrUaVHZ9ncfgmeAsqv5rgQeDJJmeeAk82sc9Q8cnI0LaPMbARwPTDK3bdXUiaV30ImY4w/T3VGJZ89H+hnZn2j2uN5hO1eX74OvO3uJclm1sc2rGKfkp3fX6bOqDfWARhKqJ4tAhZGwynA5cDlUZkJwFuEKyleBf6rHuM7KPrc4iiGG6Pp8fEZcC/hqo/FQEE9b8O2hJ18x7hpWd1+hAS1FthJOPq6BMgD5gDLo9f9orIFwINxy44DVkTDxfUU2wpCW3L5b/A3UdkDgGeq+i3U4/b7Q/T7WkTYwfVIjDF6fwrhipt3MxVjsvii6b8r/93Fla3XbVjFPiUrvz91cyEiIjFqPhIRkRglBRERiVFSEBGRGCUFERGJUVIQEZEYJQWRiJntsoo9uKatx04z6xPfQ6dIrmqR7QBEcsgOdx+U7SBEskk1BZFqRP3p325mr0fDl6Lp+WY2J+rwbY6Z9Y6md7PwjIPiaPivaFXNzeyBqM/8v5tZm6j8VWa2JFrPjCx9TRFASUEkXpuE5qNz4+ZtcfchwK+BqdG0XxO6IB9A6JDunmj6PcCLHjr0G0y4ExagH3Cvux8JfAqcFU2fCBwVrefyTH05kVTojmaRiJltdfd2SaavAk5095VRx2UfuXuemW0gdN2wM5q+1t27mNl6oJe7fxG3jj6Efu/7Re+vB1q6+y1mNhvYSugN9gmPOgMUyQbVFERS45WMV1YmmS/ixnex55zetwh9UR0NLIh67hTJCiUFkdScG/f672j8FUKvngBjgZej8TnAFQBm1tzMOlS2UjNrBhzo7nOBHwOdgL1qKyL1RUckInu0sYoPb5/t7uWXpe5jZq8RDqTGRNOuAh4ysx8B64GLo+lXA9PM7BJCjeAKQg+dyTQHpptZR0Lvtf/r7p+m7RuJ1JDOKYhUIzqnUODuG7Idi0imqflIRERiVFMQEZEY1RRERCRGSUFERGKUFEREJEZJQUREYpQUREQk5v8DfsRuwiFOUCoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING A MODEL FROM SCRATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 171us/step - loss: 2.5398 - acc: 0.5226 - val_loss: 1.6733 - val_acc: 0.6570\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 70us/step - loss: 1.3712 - acc: 0.7121 - val_loss: 1.2758 - val_acc: 0.7210\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 70us/step - loss: 1.0136 - acc: 0.7781 - val_loss: 1.1303 - val_acc: 0.7530\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 70us/step - loss: 0.7976 - acc: 0.8251 - val_loss: 1.0539 - val_acc: 0.7590\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 70us/step - loss: 0.6393 - acc: 0.8624 - val_loss: 0.9754 - val_acc: 0.7920\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 77us/step - loss: 0.5124 - acc: 0.8921 - val_loss: 0.9102 - val_acc: 0.8140\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 70us/step - loss: 0.4124 - acc: 0.9137 - val_loss: 0.8932 - val_acc: 0.8210\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 77us/step - loss: 0.3355 - acc: 0.9290 - val_loss: 0.8732 - val_acc: 0.8260\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 70us/step - loss: 0.2782 - acc: 0.9371 - val_loss: 0.9338 - val_acc: 0.8000\n",
      "2246/2246 [==============================] - 0s 59us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "partial_y_train,\n",
    "epochs=9,\n",
    "batch_size=512,\n",
    "validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7756010686194165\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy is', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different way ot handle the data (withotut hot enconding of the label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8982/8982 [==============================] - 1s 143us/step - loss: 1.7404 - acc: 0.6335\n",
      "Epoch 2/20\n",
      "8982/8982 [==============================] - 1s 76us/step - loss: 0.9350 - acc: 0.7989\n",
      "Epoch 3/20\n",
      "8982/8982 [==============================] - 1s 78us/step - loss: 0.6236 - acc: 0.8684\n",
      "Epoch 4/20\n",
      "8982/8982 [==============================] - 1s 78us/step - loss: 0.4332 - acc: 0.9081\n",
      "Epoch 5/20\n",
      "8982/8982 [==============================] - 1s 77us/step - loss: 0.3172 - acc: 0.9300\n",
      "Epoch 6/20\n",
      "8982/8982 [==============================] - 1s 78us/step - loss: 0.2494 - acc: 0.9412\n",
      "Epoch 7/20\n",
      "8982/8982 [==============================] - 1s 77us/step - loss: 0.2130 - acc: 0.9483\n",
      "Epoch 8/20\n",
      "8982/8982 [==============================] - 1s 78us/step - loss: 0.1832 - acc: 0.9510\n",
      "Epoch 9/20\n",
      "8982/8982 [==============================] - 1s 78us/step - loss: 0.1652 - acc: 0.9529\n",
      "Epoch 10/20\n",
      "8982/8982 [==============================] - 1s 79us/step - loss: 0.1613 - acc: 0.9530\n",
      "Epoch 11/20\n",
      "8982/8982 [==============================] - 1s 78us/step - loss: 0.1528 - acc: 0.9531\n",
      "Epoch 12/20\n",
      "8982/8982 [==============================] - 1s 78us/step - loss: 0.1420 - acc: 0.9526\n",
      "Epoch 13/20\n",
      "8982/8982 [==============================] - 1s 79us/step - loss: 0.1383 - acc: 0.9541\n",
      "Epoch 14/20\n",
      "8982/8982 [==============================] - 1s 78us/step - loss: 0.1315 - acc: 0.9539\n",
      "Epoch 15/20\n",
      "8982/8982 [==============================] - 1s 79us/step - loss: 0.1290 - acc: 0.9537\n",
      "Epoch 16/20\n",
      "8982/8982 [==============================] - 1s 77us/step - loss: 0.1216 - acc: 0.9550\n",
      "Epoch 17/20\n",
      "8982/8982 [==============================] - 1s 79us/step - loss: 0.1220 - acc: 0.9547\n",
      "Epoch 18/20\n",
      "8982/8982 [==============================] - 1s 79us/step - loss: 0.1167 - acc: 0.9541\n",
      "Epoch 19/20\n",
      "8982/8982 [==============================] - 1s 80us/step - loss: 0.1150 - acc: 0.9552\n",
      "Epoch 20/20\n",
      "8982/8982 [==============================] - 1s 79us/step - loss: 0.1118 - acc: 0.9557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdd6506c9e8>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='sparse_categorical_crossentropy',\n",
    "metrics=['acc'])\n",
    "model.fit(x_train,\n",
    "y_train,\n",
    "epochs=20,\n",
    "batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 140us/step\n",
      "Accuracy is 0.789848619715401\n"
     ]
    }
   ],
   "source": [
    "results =  model.evaluate(x_test, y_test)\n",
    "print('Accuracy is', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VARIOUS PARAMATERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 155us/step - loss: 3.2927 - acc: 0.2180 - val_loss: 2.8711 - val_acc: 0.2320\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 2.4604 - acc: 0.3001 - val_loss: 2.0634 - val_acc: 0.5420\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 82us/step - loss: 1.6104 - acc: 0.5965 - val_loss: 1.5190 - val_acc: 0.6290\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 1.2708 - acc: 0.6700 - val_loss: 1.3893 - val_acc: 0.6710\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 1.0945 - acc: 0.7348 - val_loss: 1.3225 - val_acc: 0.7090\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 82us/step - loss: 0.9664 - acc: 0.7685 - val_loss: 1.2741 - val_acc: 0.7230\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.8679 - acc: 0.7875 - val_loss: 1.2712 - val_acc: 0.7260\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.7896 - acc: 0.7993 - val_loss: 1.2677 - val_acc: 0.7280\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 0.7246 - acc: 0.8109 - val_loss: 1.2985 - val_acc: 0.7350\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 0.6680 - acc: 0.8220 - val_loss: 1.3257 - val_acc: 0.7170\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 0.6190 - acc: 0.8336 - val_loss: 1.3409 - val_acc: 0.7310\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 0.5778 - acc: 0.8465 - val_loss: 1.3426 - val_acc: 0.7360\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 0.5380 - acc: 0.8582 - val_loss: 1.4065 - val_acc: 0.7280\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 82us/step - loss: 0.5078 - acc: 0.8646 - val_loss: 1.4228 - val_acc: 0.7390\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 82us/step - loss: 0.4768 - acc: 0.8735 - val_loss: 1.4530 - val_acc: 0.7340\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.4515 - acc: 0.8806 - val_loss: 1.5255 - val_acc: 0.7290\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 82us/step - loss: 0.4301 - acc: 0.8887 - val_loss: 1.5287 - val_acc: 0.7250\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 0.4132 - acc: 0.8939 - val_loss: 1.5552 - val_acc: 0.7360\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.3944 - acc: 0.8994 - val_loss: 1.5987 - val_acc: 0.7240\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.3744 - acc: 0.9032 - val_loss: 1.6291 - val_acc: 0.7280\n",
      "2246/2246 [==============================] - 0s 57us/step\n",
      "0.6967943010325954\n"
     ]
    }
   ],
   "source": [
    "#NN with 4 hidden\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "partial_y_train,\n",
    "epochs=20,\n",
    "batch_size=128,\n",
    "validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "print(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 2s 225us/step - loss: 1.6194 - acc: 0.6619 - val_loss: 1.0987 - val_acc: 0.7720\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 141us/step - loss: 0.7687 - acc: 0.8361 - val_loss: 0.8835 - val_acc: 0.8060\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 139us/step - loss: 0.4591 - acc: 0.9008 - val_loss: 0.9174 - val_acc: 0.8110\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 0.3082 - acc: 0.9298 - val_loss: 0.8450 - val_acc: 0.8220\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 142us/step - loss: 0.2327 - acc: 0.9444 - val_loss: 0.9750 - val_acc: 0.7830\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 141us/step - loss: 0.1900 - acc: 0.9504 - val_loss: 0.9236 - val_acc: 0.8240\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 141us/step - loss: 0.1703 - acc: 0.9531 - val_loss: 1.1079 - val_acc: 0.7670\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 141us/step - loss: 0.1558 - acc: 0.9541 - val_loss: 0.9734 - val_acc: 0.8090\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 142us/step - loss: 0.1421 - acc: 0.9558 - val_loss: 1.1475 - val_acc: 0.7920\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 141us/step - loss: 0.1313 - acc: 0.9545 - val_loss: 1.0374 - val_acc: 0.7950\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 0.1202 - acc: 0.9573 - val_loss: 1.1235 - val_acc: 0.7890\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 143us/step - loss: 0.1191 - acc: 0.9557 - val_loss: 1.0627 - val_acc: 0.8050\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 140us/step - loss: 0.1116 - acc: 0.9548 - val_loss: 1.1508 - val_acc: 0.8000\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 158us/step - loss: 0.1061 - acc: 0.9572 - val_loss: 1.1995 - val_acc: 0.8000\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 0.0989 - acc: 0.9585 - val_loss: 1.2236 - val_acc: 0.7960\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 0.0968 - acc: 0.9567 - val_loss: 1.3059 - val_acc: 0.7860\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 0.0947 - acc: 0.9564 - val_loss: 1.3175 - val_acc: 0.8010\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 155us/step - loss: 0.0895 - acc: 0.9574 - val_loss: 1.3736 - val_acc: 0.7940\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 148us/step - loss: 0.0863 - acc: 0.9584 - val_loss: 1.3953 - val_acc: 0.7880\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 0.0823 - acc: 0.9588 - val_loss: 1.4800 - val_acc: 0.7860\n",
      "2246/2246 [==============================] - 0s 85us/step\n",
      "0.7756010686194165\n"
     ]
    }
   ],
   "source": [
    "#NN with 128 hidden\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "partial_y_train,\n",
    "epochs=20,\n",
    "batch_size=128,\n",
    "validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "print(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 142us/step - loss: 2.2729 - acc: 0.5340 - val_loss: 1.5473 - val_acc: 0.6530\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 0s 56us/step - loss: 1.2566 - acc: 0.7281 - val_loss: 1.2220 - val_acc: 0.7370\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 0s 62us/step - loss: 0.9416 - acc: 0.7983 - val_loss: 1.0808 - val_acc: 0.7740\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 64us/step - loss: 0.7337 - acc: 0.8408 - val_loss: 1.0771 - val_acc: 0.7520\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.5758 - acc: 0.8725 - val_loss: 0.9939 - val_acc: 0.7910\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.4520 - acc: 0.8996 - val_loss: 0.9645 - val_acc: 0.8060\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.3548 - acc: 0.9212 - val_loss: 0.9455 - val_acc: 0.8150\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.2898 - acc: 0.9356 - val_loss: 0.9613 - val_acc: 0.8140\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.2409 - acc: 0.9427 - val_loss: 0.9795 - val_acc: 0.8060\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 0s 60us/step - loss: 0.2052 - acc: 0.9494 - val_loss: 0.9928 - val_acc: 0.8100\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 0s 60us/step - loss: 0.1812 - acc: 0.9510 - val_loss: 1.0575 - val_acc: 0.8050\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.1638 - acc: 0.9529 - val_loss: 1.0509 - val_acc: 0.8130\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.1541 - acc: 0.9544 - val_loss: 1.1205 - val_acc: 0.7910\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.1433 - acc: 0.9549 - val_loss: 1.0879 - val_acc: 0.8010\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 0s 60us/step - loss: 0.1359 - acc: 0.9560 - val_loss: 1.1180 - val_acc: 0.8020\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.1273 - acc: 0.9559 - val_loss: 1.1377 - val_acc: 0.7980\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.1235 - acc: 0.9574 - val_loss: 1.1353 - val_acc: 0.8050\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.1178 - acc: 0.9570 - val_loss: 1.1930 - val_acc: 0.7920\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 0s 60us/step - loss: 0.1171 - acc: 0.9568 - val_loss: 1.1914 - val_acc: 0.7960\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.1129 - acc: 0.9582 - val_loss: 1.2454 - val_acc: 0.7930\n",
      "2246/2246 [==============================] - 0s 52us/step\n",
      "0.7702582368655387\n"
     ]
    }
   ],
   "source": [
    "#NN with 128 hidden\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "partial_y_train,\n",
    "epochs=20,\n",
    "batch_size=128,\n",
    "validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "print(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 178us/step - loss: 1.8416 - acc: 0.6443 - val_loss: 1.2073 - val_acc: 0.7410\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 82us/step - loss: 0.9336 - acc: 0.8066 - val_loss: 0.9663 - val_acc: 0.8040\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 82us/step - loss: 0.6369 - acc: 0.8703 - val_loss: 0.8537 - val_acc: 0.8210\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 86us/step - loss: 0.4545 - acc: 0.9054 - val_loss: 0.8045 - val_acc: 0.8350\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 86us/step - loss: 0.3392 - acc: 0.9266 - val_loss: 0.7949 - val_acc: 0.8370\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 0.2651 - acc: 0.9401 - val_loss: 0.8157 - val_acc: 0.8250\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 0.2178 - acc: 0.9466 - val_loss: 0.8250 - val_acc: 0.8270\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.1828 - acc: 0.9501 - val_loss: 0.8522 - val_acc: 0.8250\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 86us/step - loss: 0.1622 - acc: 0.9541 - val_loss: 0.9063 - val_acc: 0.8190\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 0.1489 - acc: 0.9539 - val_loss: 0.8964 - val_acc: 0.8170\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.1345 - acc: 0.9565 - val_loss: 0.9659 - val_acc: 0.8140\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 0.1301 - acc: 0.9559 - val_loss: 0.9897 - val_acc: 0.8110\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.1192 - acc: 0.9582 - val_loss: 1.0405 - val_acc: 0.8030\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 0.1173 - acc: 0.9565 - val_loss: 1.0157 - val_acc: 0.8080\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 0.1133 - acc: 0.9572 - val_loss: 1.0281 - val_acc: 0.8130\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.1101 - acc: 0.9574 - val_loss: 1.1217 - val_acc: 0.8020\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 86us/step - loss: 0.1069 - acc: 0.9564 - val_loss: 1.1148 - val_acc: 0.7950\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.1052 - acc: 0.9577 - val_loss: 1.1335 - val_acc: 0.8020\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 86us/step - loss: 0.1050 - acc: 0.9570 - val_loss: 1.1362 - val_acc: 0.7970\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 0.1033 - acc: 0.9572 - val_loss: 1.1913 - val_acc: 0.8000\n",
      "2246/2246 [==============================] - 0s 63us/step\n",
      "0.7751558326178115\n"
     ]
    }
   ],
   "source": [
    "#NN with 1 hidden layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "#model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "partial_y_train,\n",
    "epochs=20,\n",
    "batch_size=128,\n",
    "validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "print(results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 185us/step - loss: 1.9002 - acc: 0.6118 - val_loss: 1.2715 - val_acc: 0.7230\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 0.9874 - acc: 0.7783 - val_loss: 1.0645 - val_acc: 0.7640\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 0.6712 - acc: 0.8513 - val_loss: 1.0057 - val_acc: 0.7790\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 0.4721 - acc: 0.8983 - val_loss: 0.9443 - val_acc: 0.8150\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 96us/step - loss: 0.3415 - acc: 0.9216 - val_loss: 0.9810 - val_acc: 0.8110\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.2725 - acc: 0.9385 - val_loss: 1.0810 - val_acc: 0.7990\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 86us/step - loss: 0.2190 - acc: 0.9489 - val_loss: 1.1847 - val_acc: 0.7810\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 97us/step - loss: 0.1945 - acc: 0.9504 - val_loss: 1.1169 - val_acc: 0.7990\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 0.1722 - acc: 0.9538 - val_loss: 1.0903 - val_acc: 0.8100\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 0.1588 - acc: 0.9544 - val_loss: 1.1146 - val_acc: 0.8000\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 0.1499 - acc: 0.9569 - val_loss: 1.2028 - val_acc: 0.7850\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 92us/step - loss: 0.1432 - acc: 0.9544 - val_loss: 1.2199 - val_acc: 0.7940\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 0.1316 - acc: 0.9563 - val_loss: 1.2919 - val_acc: 0.7810\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 0.1268 - acc: 0.9562 - val_loss: 1.1942 - val_acc: 0.8070\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.1237 - acc: 0.9551 - val_loss: 1.2524 - val_acc: 0.7930\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 0.1158 - acc: 0.9557 - val_loss: 1.2635 - val_acc: 0.7960\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 96us/step - loss: 0.1168 - acc: 0.9560 - val_loss: 1.3013 - val_acc: 0.7990\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.1079 - acc: 0.9583 - val_loss: 1.3201 - val_acc: 0.7820\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 0.1028 - acc: 0.9573 - val_loss: 1.3591 - val_acc: 0.7880\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.1005 - acc: 0.9583 - val_loss: 1.3927 - val_acc: 0.7790\n",
      "2246/2246 [==============================] - 0s 73us/step\n",
      "0.770258236918615\n"
     ]
    }
   ],
   "source": [
    "#NN with 3 hidden layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "model.fit(partial_x_train,\n",
    "partial_y_train,\n",
    "epochs=20,\n",
    "batch_size=128,\n",
    "validation_data=(x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "print(results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
