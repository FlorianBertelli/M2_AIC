{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "agGqavgfg0KS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berte\\Desktop\\M2_AIC\\NLP\\Projet\\Les_miserables\n"
     ]
    }
   ],
   "source": [
    "cd ./Les_miserables/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C s'appelle Windows\n",
      " Le num‚ro de s‚rie du volume est 28E6-BFFF\n",
      "\n",
      " R‚pertoire de C:\\Users\\berte\\Desktop\\M2_AIC\\NLP\\Projet\\Les_miserables\n",
      "\n",
      "08/11/2019  09:36    <DIR>          .\n",
      "08/11/2019  09:36    <DIR>          ..\n",
      "08/11/2019  09:38           480ÿ885 miserable.txt\n",
      "               1 fichier(s)          480ÿ885 octets\n",
      "               2 R‚p(s)  137ÿ460ÿ723ÿ712 octets libres\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "colab_type": "code",
    "id": "jApvREm-g0Kq",
    "outputId": "f2fb3231-3df2-479f-e962-aaeb8e737328"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462162\n"
     ]
    }
   ],
   "source": [
    "# Load Larger LSTM network and generate text\n",
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import os\n",
    "import nltk\n",
    "# load ascii text and covert to lowercase\n",
    "\n",
    "full_text = []\n",
    "\n",
    "for filename in os.listdir(os.getcwd()):\n",
    "    if (filename!='sample_data' and filename!='.config' and filename !='.ipynb_checkpoints'):\n",
    "        raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "        full_text.append(raw_text.lower())\n",
    "flat_list = (', '.join(full_text))\n",
    "print(len(flat_list))\n",
    "flat_list = flat_list.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1QfS_gAxg0K2"
   },
   "outputs": [],
   "source": [
    "whitelist = set('abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "answer = flat_list.replace(\"é\" , \"e\")\n",
    "answer = answer.replace(\"à\" , \"a\")\n",
    "answer= answer.replace(\"è\" , \"e\")\n",
    "answer= answer.replace(\"ê\" , \"e\")\n",
    "answer = ''.join(filter(whitelist.__contains__, answer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "a64N2WGBg0K_",
    "outputId": "8502226b-32f1-4e99-c7fa-c47a856f9a52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435632"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "lT5Pc3c6g0LG",
    "outputId": "1f1c0e98-f2c5-402c-c813-8d6508247df9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\berte\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "tokens = nltk.word_tokenize(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "NrSbRB0qg0LO",
    "outputId": "de48170c-c7c0-4cc3-e0da-6cfc20a3dbf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en', 'm', 'charlesfranoisbienvenu', 'myriel', 'etait', 'eveque', 'de', 'digne', 'cetait', 'un', 'vieillard', 'denviron', 'soixantequinze', 'ans', 'il', 'occupait', 'le', 'siege', 'de', 'digne', 'depuis', 'quoique', 'ce', 'detail', 'ne', 'touche', 'en', 'aucune', 'maniere', 'au', 'fond', 'meme', 'de', 'ce', 'que', 'nous', 'avons', 'a', 'raconter', 'il', 'nest', 'peutetre', 'pas', 'inutile', 'ne', 'ftce', 'que', 'pour', 'etre', 'exact', 'en', 'tout', 'dindiquer', 'ici', 'les', 'bruits', 'et', 'les', 'propos', 'qui', 'avaient', 'couru', 'sur', 'son', 'compte', 'au', 'moment', 'o', 'il', 'etait', 'arrive', 'dans', 'le', 'diocese', 'vrai', 'ou', 'faux', 'ce', 'quon', 'dit', 'des', 'hommes', 'tient', 'souvent', 'autant', 'de', 'place', 'dans', 'leur', 'vie', 'et', 'surtout', 'dans', 'leur', 'destinee', 'que', 'ce', 'quils', 'font', 'm']\n"
     ]
    }
   ],
   "source": [
    "print(tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "JSX0Dr6_g0LS",
    "outputId": "06c2c189-5e4f-427c-9b75-76adca0df205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 76025\n",
      "Unique Tokens: 12065\n"
     ]
    }
   ],
   "source": [
    "print('Total Tokens: %d' % len(tokens))\n",
    "print('Unique Tokens: %d' % len(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ly8oTPDDSuxD"
   },
   "outputs": [],
   "source": [
    "# save tokens to file, one dialog per line\n",
    "def save_doc(lines, filename):\n",
    "\tdata = '\\n'.join(lines)\n",
    "\tfile = open(filename, 'w')\n",
    "\tfile.write(data)\n",
    "\tfile.close()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "FD2cPUIyRybU",
    "outputId": "4dbca1b9-0fae-4c13-fd84-54b906359faa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 75974\n"
     ]
    }
   ],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "\n",
    "# organize into sequences of tokens\n",
    "length = 50 + 1\n",
    "sequences = list()\n",
    "for i in range(length, len(tokens)):\n",
    "\t# select sequence of tokens\n",
    "\tseq = tokens[i-length:i]\n",
    "\t# convert into a line\n",
    "\tline = ' '.join(seq)\n",
    "\t# store\n",
    "\tsequences.append(line)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "\n",
    "# save sequences to file\n",
    "out_filename = 'miserable_sentences.txt'\n",
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QwElf8I3g0La"
   },
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# load\n",
    "in_filename = 'miserable_sentences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "\n",
    "lines = lines[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iIlPYvO2g0Lg"
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Ewo2KtxkWLkE",
    "outputId": "90c98efe-c862-48b8-9509-173b9171e2bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "print(len(nltk.word_tokenize(lines[5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHVOxZb8g0Li"
   },
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "sequences = tokenizer.texts_to_sequences(lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "Qicnhq7ng0Ll",
    "outputId": "5fc06ae7-52af-4c0a-b2e4-75b48ce331e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149, 1, 80, 85, 10, 150, 703, 734, 75, 6, 602, 4, 601, 1, 80, 92, 165, 13, 445, 21, 428, 12, 409, 404, 19, 207, 56, 1, 13, 9, 44, 218, 5, 393, 6, 103, 83, 20, 358, 21, 357, 9, 22, 77, 353, 12, 31, 254, 145, 7, 278]\n"
     ]
    }
   ],
   "source": [
    "print(sequences[5])\n",
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "NJyQ9jdmUIbq",
    "outputId": "51a2094e-5b59-4e11-8a50-f7458a0fcff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en m charlesfranoisbienvenu myriel etait eveque de digne cetait un vieillard denviron soixantequinze ans il occupait le siege de digne depuis quoique ce detail ne touche en aucune maniere au fond meme de ce que nous avons a raconter il nest peutetre pas inutile ne ftce que pour etre exact en\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oaj95wZag0Ln"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "# separate into input and output\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "IzY3VUJ2QS-P",
    "outputId": "fd6750e3-b00e-4fd9-c551-8bde23bffa40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([145]),)\n",
      "145\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.where(y[3]==1))\n",
    "print(X[4][49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "colab_type": "code",
    "id": "el5pWxbng0Ls",
    "outputId": "daa38490-8354-4035-a833-fc1ebc50baaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 50)            626750    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12535)             1266035   \n",
      "=================================================================\n",
      "Total params: 2,043,685\n",
      "Trainable params: 2,043,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "FWPwajrBg0L1",
    "outputId": "e3f4e3d8-0b9c-4aca-c234-a3742663e790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dme par le diableun jour une douairiere de la variete impertinente qui se croit spirituelle lui adressa cette saillie monseigneur on demande quand votre grandeur aura le bonnet rouge oh oh voila une grosse couleur repondit leveque heureusement que ceux qui la meprisent dans un bonnet la venerent dans un chapeaui\n",
      "\n",
      "une restrictionon risquerait fort et en allant avec une idoltrie lchant femme et lorateur nommee a terre et le pere madeleine etait devenue desole rendirent\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "\t# open the file as read only\n",
    "\tfile = open(filename, 'r')\n",
    "\t# read all text\n",
    "\ttext = file.read()\n",
    "\t# close the file\n",
    "\tfile.close()\n",
    "\treturn text\n",
    "\n",
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "\tresult = list()\n",
    "\tin_text = seed_text\n",
    "\t# generate a fixed number of words\n",
    "\tfor _ in range(n_words):\n",
    "\t\t# encode the text as integer\n",
    "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "\t\t# truncate sequences to a fixed length\n",
    "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "\t\t# predict probabilities for each word\n",
    "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
    "\t\t# map predicted word index to word\n",
    "\t\tout_word = ''\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index == yhat:\n",
    "\t\t\t\tout_word = word\n",
    "\t\t\t\tbreak\n",
    "\t\t# append to input\n",
    "\t\tin_text += ' ' + out_word\n",
    "\t\tresult.append(out_word)\n",
    "\treturn ' '.join(result)\n",
    "\n",
    "\n",
    "seq_length = len(lines[0].split()) - 1\n",
    "\n",
    "# load the model\n",
    "\n",
    "model = load_model(\"../WEIGHT_NLP2/model_fr_V4.h5\")\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer = load(open(\"../WEIGHT_NLP2/tokenizer_fr.pkl\", 'rb'))\n",
    "\n",
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text,25)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "word_level_lstm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
